---
title: "NbS Stocktake - AI Data Extraction from Peer-Reviewed Papers"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# ============================================================================
# NbS STOCKTAKE - AUTOMATED DATA EXTRACTION PIPELINE
# ============================================================================
# 
# WORKFLOW:
#   PART 1: Setup & Configuration
#   PART 2: Load pre-extracted text (from previous PDF extraction)
#   PART 3: Define extraction prompts for each variable
#   PART 4: GPT Extraction (variable by variable)
#   PART 5: Save Results
#
# ============================================================================

# Load libraries
```{r libraries}
library(pdftools)
library(stringr)
library(dplyr)
library(tibble)
library(tidyr)
library(purrr)
library(DT)
library(glue)
library(jsonlite)
library(httr)
library(readr)
library(writexl)
library(ellmer)
```

# ============================================================================
# PART 1: CONFIGURATION
# ============================================================================

```{r config}
# ----- API Configuration -----
# Set your OpenAI API key (or use environment variable)

openai_api_key <- Sys.getenv("NBS_API_KEY")

# Model selection
GPT_MODEL <- "gpt-5-nano"  # Cost-effective option

# ----- Extraction Configuration -----
# Set to TRUE to use full text, FALSE to use methods section only
USE_FULL_TEXT <- TRUE

# Batch size for API calls
CHUNK_SIZE <- 30

# Maximum characters to send per paper (to avoid token limits)


# Output directory
OUT_DIR <- "C:/PDFs_extracted_text/extraction_results"
dir.create(OUT_DIR, showWarnings = FALSE, recursive = TRUE)



# Safe API call wrapper
safe_chat <- function(prompt, model = GPT_MODEL) {
  tryCatch({
    chat <- ellmer::chat_openai(model = model)
    resp <- chat$chat(prompt)
    list(response = trimws(resp), error = NA_character_)
  }, error = function(e) {
    list(response = NA_character_, error = conditionMessage(e))
  })
}

# Add this BEFORE load_txt_file
safe_stem <- function(x) {
  x %>%
    tools::file_path_sans_ext() %>%
    str_replace_all("[^A-Za-z0-9]+", "_") %>%
    str_replace_all("_+", "_") %>%
    str_replace_all("^_|_$", "")
}


```

# ============================================================================
# PART 2: LOAD DATA
# ============================================================================

```{r load_data}

library(readxl)

Grey_lit_tbl <- read_excel("C:/Users/mlolita/OneDrive - CGIAR/Alliance - ClimateActionNetZero - 1_Projects/D591_Rural-Scan_NBS/2_Technical_&_Data/Stocktake Review/GPT Literature Discovery/GPT Search Results.xlsx")
# Select text column based on configuration
articles_tbl <- Grey_lit_tbl %>%
  mutate(
    Text_For_Extraction = `GPT Summary`
  )
# Filter to papers with extractable text
papers_to_extract <- articles_tbl %>%
  filter(!is.na(Text_For_Extraction), nchar(Text_For_Extraction) > 20)

message(glue("Papers ready for extraction: {nrow(papers_to_extract)}"))
```




# ============================================================================
# PART 3: EXTRACTION PROMPTS
# ============================================================================

```{r prompts}
# ============================================================================
# PART 3: EXTRACTION PROMPTS - REVISED VERSION
# ============================================================================

# ----- Prompt: NbS Subpractice -----
prompt_nbs_subpractice <- function(txt, nbs_practice) {
  glue('
Read the following text from a peer-reviewed paper on Nature-based Solutions.
The paper is about: {nbs_practice}

Identify if the paper specifies a more precise NbS subpractice beyond the general category.

Examples of subpractices:
- Agroforestry: FMNR, Multistrata systems, Alley cropping, Silvopasture, Parklands, Windbreaks, Riparian buffers, Home gardens, Forest farming, Shelterbelts
- Forest restoration: Natural regeneration, Assisted natural regeneration, Active planting, Enrichment planting, Afforestation
- Wetland management: Peatland restoration, Floodplain restoration, Mangrove restoration, Constructed wetlands
- Water harvesting: Check dams, Contour bunds, Farm ponds, Terracing, Swales

Extract the specific subpractice(s) as named in the paper.
If multiple subpractices, separate with semicolons (;) with NO line breaks.
If only the general NbS practice is mentioned without specific subpractices, return NA.

TEXT:
"""
{txt}
"""

Output only the subpractice name(s) or NA on a single line. No explanation. No line breaks within the answer.')
}

# ----- Prompt: Input Variables -----
prompt_input_variables <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Extract input variables/data layers used in the spatial analysis or suitability model.


IMPORTANT: 
- Do NOT include the NbS practice itself (e.g., "agroforestry", "wetland restoration") as an input variable.
- Only extract data layers used to DETERMINE suitability.

Format: Variable Name; Variable Name; ...

CRITICAL: Output must be on a SINGLE LINE with semicolons separating items. NO line breaks within the output. Do not extract sources only variable names. 

If no input variables described, return NA.

TEXT:
"""
{txt}
"""

Output only the variable list with categories or NA. Single line only. No explanation.')
}

# ----- Prompt: Input Variable Resolution -----
prompt_input_resolution <- function(txt, input_variables) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Previously extracted input variables:
{input_variables}

For EACH variable listed above, extract its spatial resolution as explicitly stated in the text.

Resolution formats include:
- Pixel/raster: 30m, 250m, 1km, 30 arc-seconds
- Vector/admin: county-level, district-level, parcel-level, admin level 2
- Grid: 10km x 10km grid spacing
- Other: basin level, watershed level

Format: Variable Name: Resolution; Variable Name: Resolution; ...

Rules:
- Only include resolution if EXPLICITLY stated for that variable
- If resolution not mentioned for a variable, write "not specified"
- If no resolution information exists in the text at all, return NA

CRITICAL: Output must be on a SINGLE LINE with semicolons separating items. NO line breaks within the output.

TEXT:
"""
{txt}
"""

Output only variable-resolution pairs or NA. Single line only. No explanation.')
}

# ----- Prompt: Input Variable Source ----- [NEW PROMPT]
prompt_input_source <- function(txt, input_variables) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Previously extracted input variables:
{input_variables}

For EACH variable, extract the DATA SOURCE as stated in the text.

Look for:
1. Named databases/portals: USGS Earth Explorer, WorldClim, SoilGrids, FAO GeoNetwork, MODIS, Landsat, Sentinel, ASTER, SRTM
2. Institutional sources: National agencies, meteorological services, soil surveys (e.g., gSSURGO, NRCS)
3. Derived from other data: "derived from DEM", "calculated from Landsat"
4. Field collection: "field surveys", "soil sampling", "ground measurements"
5. Previous studies: citations to other papers

Also note ACCESS TYPE if mentioned:
- open access / freely available / public
- proprietary / restricted
- not specified

Format: Variable Name: Source Name (access type); Variable Name: Source Name (access type); ...

Example: "Elevation: ASTER DEM via USGS (open access); Soil pH: Field sampling (not specified); Rainfall: WorldClim (open access)"

If source not stated for a variable, write "NA"
If no sources mentioned at all, return NA.

CRITICAL: Output must be on a SINGLE LINE with semicolons separating items. NO line breaks.

TEXT:
"""
{txt}
"""

Output only variable-source pairs or NA. Single line only. No explanation.')
}

# ----- Prompt: Spatial Method Name -----
prompt_spatial_method <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Extract the spatial analysis method(s) used to identify suitable/priority areas.

Some examples include : MCDA, AHP,Weighted linear combination,goal programming,random foress, overlay analysis etc 

Extract the exact method used in the article if there are more than one extract a semicolumn separated list. 



If multiple methods, separate with semicolons (;).
CRITICAL: Output must be on a SINGLE LINE. NO line breaks.
If method not described, return NA.

TEXT:
"""
{txt}
"""

Output only method name(s) or NA. Single line only. No explanation.')
}

# ----- Prompt: Spatial Method Source ----- [REVISED]
prompt_method_source <- function(txt, Spatial_Method) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Spatial method identified: {Spatial_Method}

Extract sources/references for the spatial methodology used.

Look for THREE types of sources:

1. CRITICAL MAIN METHODOLOGICAL REFERENCES (citations for the method):
   - Format as: "Reference: Author et al., Year"
   - Example: "Reference: Saaty, 1980" for AHP
   - Example: "Reference: FAO, 1976" for land evaluation

2. URLS (if any direct links provided):
   - Software documentation URLs
   - Online tool URLs
   - DOI links for methods

3. CODE/DATA REPOSITORIES (if mentioned):
   - GitHub repositories
   - Zenodo archives
   - Supplementary materials with code
   - Look for: "code available at", "scripts provided", "repository"

Format each type clearly:
- Reference: Author Year; Reference: Author Year
- URL: https://...; URL: https://...
- Repository: https://github.com/...

If no sources of a type exist, omit that type.
If no sources at all, return NA.

CRITICAL: Output on a SINGLE LINE with semicolons separating items. NO line breaks.

TEXT:
"""
{txt}
"""

Output only sources or NA. Single line only. No explanation.')
}

# ----- Prompt: Method Validation -----
prompt_method_validation <- function(txt, Spatial_Method) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Spatial method used: {Spatial_Method}

Identify if and how the authors VALIDATED their model outputs or suitability maps.

Validation approaches include:
- Field verification / ground-truthing (visited sites to confirm predictions)
- Comparison with existing NbS sites or known locations
- Cross-validation (k-fold, leave-one-out, train-test split)
- Cross-evaluation with land use/land cover categories
- Independent test dataset
- Expert review or stakeholder validation
- Sensitivity analysis
- Comparison with other studies/maps
- AHP consistency ratio check (CR < 0.1 threshold)
- Proximity-based validation (proximity analysis to known features)

Extract the validation approach(es) as described in the paper.
If multiple approaches, separate with semicolons (;).
CRITICAL: Output must be on a SINGLE LINE. NO line breaks.
If no validation is mentioned or performed, return NA.

TEXT:
"""
{txt}
"""

Output only the validation method(s) or NA. Single line only. No explanation.')
}


# ----- Prompt: Analysis Resolution -----
prompt_analysis_resolution <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

What spatial resolution or grid cell size was used for the ANALYSIS (not just input data)?

Look for phrases like:
- "analysis conducted at X resolution"
- "resampled to X"
- "grid spacing of X"
- "cell size of X"
- "aggregated to X km grid"
- "vector grid spacing"

Resolution formats:
- Raster: 30m, 100m, 1km, 30 arc-seconds
- Grid: 1km x 1km, 10km x 10km grid cells
- Admin: county-level, district-level

If multiple resolutions used for different analyses, list all.
CRITICAL: Output on a SINGLE LINE. NO line breaks.
If not explicitly stated, return NA.

TEXT:
"""
{txt}
"""

Output only the analysis resolution or NA. Single line only. No explanation.')
}

# ----- Prompt: Tool -----
prompt_tool <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Identify specific NAMED TOOLS, PLATFORMS, or DECISION SUPPORT SYSTEMS used for the spatial analysis.

INCLUDE these types of tools:
- Ecosystem service tools: InVEST, Co$ting Nature, WaterWorld, ARIES, LUCI
- Conservation planning: Marxan, Zonation, prioritizr, ConsNet
- Species/habitat modeling: MaxEnt, biomod2, ENMeval
- Carbon/climate tools: COMET-Planner, COMET-Farm, CBP, Ex-Act
- Named decision support systems: FADSS, targetCSA, LUMENS
- Custom web applications with specific names

EXCLUDE (do not extract):
- General GIS software: ArcGIS, QGIS, GRASS GIS, ArcGIS Pro
- Programming languages/environments: R, Python, MATLAB
- Cloud platforms: Google Earth Engine (unless a specific named app)
- Data sources/portals: USGS, FAO GeoNetwork, WorldClim, SoilGrids
- Image processing software: ERDAS Imagine, ENVI
- Generic database software

If multiple tools, separate with semicolons (;).
CRITICAL: Output on a SINGLE LINE. NO line breaks.
If only general software was used (no specific named tools), return NA.

TEXT:
"""
{txt}
"""

Output only specific tool name(s) or NA. Single line only. No explanation.')
}

# ----- Prompt: Tool Source ----- [NEW PROMPT]
prompt_tool_source <- function(txt, tool) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Tool(s) identified: {tool}

For each tool, extract the SOURCE or URL if provided in the text. Only extract sources for the tools previously extracted do not include new ones. 

Look for:
- Direct URLs to the tool
- DOI references for the tool
- Citations describing the tool
- GitHub/repository links

Also check the References section for tool citations. 

Known tool URLs (use if tool mentioned but URL not in text):
- InVEST: https://naturalcapitalproject.stanford.edu/software/invest
- Marxan: https://marxansolutions.org/
- COMET-Planner: http://comet-planner.com/
- MaxEnt: https://biodiversityinformatics.amnh.org/open_source/maxent/

Format: Tool Name: URL or Citation; Tool Name: URL or Citation

If tool has no source in text and is not in known list, write "Tool Name: NA". Look for sources only for the tools exactred before, do not extract new tools. 
CRITICAL: Output on a SINGLE LINE. NO line breaks.

TEXT:
"""
{txt}
"""

Output only tool-source pairs or NA. Single line only. No explanation.')
}

# ----- Prompt: Output -----
prompt_output <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Extract the FINAL geospatial outputs/variables/products from the analysis.Detail each output in 1-2 short sentences

Focus on FINAL deliverable, not intermediate steps.
CRITICAL: Output on a SINGLE LINE with semicolons separating items. NO line breaks.
If no clear outputs described, return NA.

TEXT:
"""
{txt}
"""

Output only the output description(s) or NA. Single line only. No explanation.')
}

# ----- Prompt: Output Resolution -----
prompt_output_resolution <- function(txt, outputs) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Final outputs produced: {outputs}

For EACH output type, extract its spatial resolution as stated in the text.

Resolution may be expressed as:
- Raster: 30m, 100m, 1km, 30 arc-seconds
- Grid: 1km x 1km spacing, 10km grid cells
- Admin unit: county-level, district-level, national
- Vector: parcel-level, watershed-level, polygon-based

Format: Output type: Resolution; Output type: Resolution

If resolution not explicitly stated for an output, write "not specified".
CRITICAL: Output on a SINGLE LINE. NO line breaks.
If no resolution information at all, return NA.

TEXT:
"""
{txt}
"""

Output only output-resolution pairs or NA. Single line only. No explanation.')
}

# ----- Prompt: Climate Risk Assessment ----- [REVISED FOR MORE DETAIL]
prompt_climate_risk <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Assess whether and how CLIMATE RISK is incorporated in the analysis.

Check for:

 CLIMATE RISK FRAMING:
- Vulnerability assessment (exposure, sensitivity, adaptive capacity)
- Hazard mapping (flood zones, drought-prone areas)
- Climate adaptation targeting
- Resilience building


Format your response as:
"Yes: [Brief description of how climate is incorporated]" 
OR
"No"

Include specifics: which climate variables, which scenarios, which time periods.

CRITICAL: Output on a SINGLE LINE. NO line breaks within the answer.

TEXT:
"""
{txt}
"""

Output only Yes with description, or No. Single line only. No explanation.')
}

# ----- Prompt: Economics -----
prompt_economics <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Determine if ECONOMIC considerations are incorporated in the OUTPUT analysis.

Look for:

1. ECONOMIC INPUTS:
- Cost data (implementation costs, maintenance costs)
- Economic returns (crop yields, timber value, income)
- Market access, farm profitability
- Land values, opportunity costs

2. ECONOMIC OUTPUTS:
- Cost-benefit analysis results
- Return on investment (ROI)
- Net present value (NPV)
- Cost-effectiveness ratios
- Economic suitability scores

3. ECONOMIC FRAMING:
- Economic viability as selection criterion
- Profitability considerations
- Livelihood impacts
- Payment for ecosystem services

Format your response as:
"Yes: Details" explaining: What economic aspects are considered, How they are integrated (input, constraint, output), Any quantitative economic metrics or values in a very small narrative paragraph

OR simply "No" if economics not considered.

CRITICAL: Output on a SINGLE LINE. NO line breaks within the answer.

TEXT:
"""
{txt}
"""

Output only Yes with details, or No. Single line only. No explanation.')
}

# ----- Prompt: Geographic Scope -----
prompt_geographic_scope <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Identify the GEOGRAPHIC SCOPE of the analysis.

Scale categories:
- Local: site, farm, small watershed (<1000 km²), municipality, village
- Sub-national: region, province, state, district, large watershed, river basin
- National: entire country
- Multi-country: transboundary region, multiple countries
- Continental: entire continent or major portion
- Global: worldwide

Extract the specific COUNTRY LOCATION NAME(S) mentioned.

Format: Scale category: Location name(s)
Example: "Sub-national: Ethiopia"
Example: "National: Kenya"
Example: "Multi-country: South Asia;Kenya"
Example: "Sub-national: Iceland"

Include all geographic areas mentioned if analysis covers multiple scales.
CRITICAL: Output on a SINGLE LINE. NO line breaks.
If no geographic information, return NA.

TEXT:
"""
{txt}
"""

Output only the geographic scope or NA. Single line only. No explanation.')
}

# ----- Prompt: Narrative -----
prompt_narrative <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Write a concise summary (maximum 150 words) describing the spatial prioritisation approach.

Include these elements IN ORDER:
1. The NbS practice(s) addressed
2. Main input variables and data sources (list key ones with sources if mentioned)
3. The spatial method used and how variables were combined
4. Validation approach and key results (if any)
5. Main outputs produced and their resolution
6. Geographic scope (scale and location)
7. Whether climate risk or economic considerations were included (briefly)

Writing guidelines:
- Use third person, past tense
- Only include information EXPLICITLY stated in the text
- Do not infer or assume information not present
- Be specific: include numbers, percentages, method names, and resolutions where available
- Do not include recommendations or implications
- Write as a single flowing paragraph, no bullet points

TEXT:
"""
{txt}
"""

Output only the narrative paragraph (max 150 words). No additional commentary.')
}

# ----- Prompt: Code/Data Availability ----- [NEW PROMPT]
prompt_code_data_availability <- function(txt) {
  glue('
Read the following text from a peer-reviewed paper on NbS spatial prioritisation.

Check for CODE and DATA availability statements.

Look for:
1. CODE REPOSITORIES:
- GitHub links
- GitLab links
- Zenodo archives
- Figshare
- "Code available at..."
- "Scripts provided in supplementary..."

2. DATA REPOSITORIES:
- Data DOIs
- Dryad
- Zenodo data
- "Data available at..."
- Supplementary data files

3. AVAILABILITY STATEMENTS:
- "Data/code available upon request"
- "All data used are publicly available"
- Specific data availability sections

Format: 
Code: [URL or description]; Data: [URL or description]

If nothing found, return NA.
CRITICAL: Output on a SINGLE LINE. NO line breaks.

TEXT:
"""
{txt}
"""

Output only availability information or NA. Single line only. No explanation.')
}
```

# ============================================================================
# PART 4: EXTRACTION FUNCTIONS
# ============================================================================

```{r extraction_functions}
# ----- Single variable extractor -----
extract_single_variable <- function(papers_df, prompt_fn, var_name, 
                                    depends_on = NULL, chunk_size = CHUNK_SIZE) {
  
  n_papers <- nrow(papers_df)
  results <- vector("character", n_papers)
  
  pb <- txtProgressBar(min = 0, max = n_papers, style = 3)
  
  for (i in seq_len(n_papers)) {
    txt <- papers_df$Text_For_Extraction[i]
    
    # Build prompt - handle dependencies
    if (is.null(depends_on)) {
      # Simple prompt with just text
      if (var_name == "NbS_Subpractice") {
        prompt <- prompt_fn(txt, papers_df$NbS_Practice[i] %||% "Unknown")
      } else {
        prompt <- prompt_fn(txt)
      }
    } else {
      # Prompt depends on previously extracted variable
      dep_value <- papers_df[[depends_on]][i] %||% "NA"
      prompt <- prompt_fn(txt, dep_value)
    }
    
    # Call API
    resp <- safe_chat(prompt)
    
    if (!is.na(resp$error)) {
      results[i] <- NA_character_
      warning(glue("Error extracting {var_name} for paper {i}: {resp$error}"))
    } else {
      results[i] <- resp$response
    }
    
    setTxtProgressBar(pb, i)
    Sys.sleep(0.5)  # Rate limiting
  }
  
  close(pb)
  results
}

# ----- Batch variable extractor (for simple prompts) -----
extract_batch_variable <- function(papers_df, prompt_fn, var_name, 
                                   chunk_size = CHUNK_SIZE) {
  
  n_papers <- nrow(papers_df)
  results <- vector("character", n_papers)
  
  idx <- seq_len(n_papers)
  chunks <- split(idx, ceiling(idx / chunk_size))
  
  pb <- txtProgressBar(min = 0, max = length(chunks), style = 3)
  
  for (c in seq_along(chunks)) {
    chunk_idx <- chunks[[c]]
    
    for (i in chunk_idx) {
      txt <- papers_df$Text_For_Extraction[i]
      
      if (var_name == "NbS_Subpractice") {
        prompt <- prompt_fn(txt, papers_df$NbS_Practice[i] %||% "Unknown")
      } else {
        prompt <- prompt_fn(txt)
      }
      
      resp <- safe_chat(prompt)
      results[i] <- if (!is.na(resp$error)) NA_character_ else resp$response
      
      Sys.sleep(0.3)
    }
    
    setTxtProgressBar(pb, c)
  }
  
  close(pb)
  results
}
```

# ============================================================================
# PART 5: RUN EXTRACTION
# ============================================================================

```{r run_extraction, eval=FALSE}
# ============================================================================
# PART 5: SEQUENTIAL EXTRACTION WORKFLOW
# ============================================================================
# Updated to include: Input_Variable_Source, Analysis_Resolution,
# Spatial_Method_Source, Tool_Source, Climate_Risk_Assessment, Economics
# Removed: Method_Performance
# ============================================================================

# Initialize results dataframe with metadata
extraction_results <- papers_to_extract %>%
  select(
    `NbS Group`, 
    `Source (title)`,
    `Organisation / authoring body`,
    `Document type`
  )

# ----- Extract each variable sequentially -----
  
  # === NbS Subpractice ===
  message("\n=== Extracting NbS Subpractice ===")
  extraction_results$NbS_Subpractice <- extract_single_variable(
    papers_to_extract, 
    prompt_nbs_subpractice, 
    "NbS_Subpractice"
  )
  
  # === Input Variables ===
  message("\n=== Extracting Input Variables ===")
  extraction_results$Input_Variables <- extract_single_variable(
    papers_to_extract, 
    prompt_input_variables, 
    "Input_Variables"
  )
  
  # Add Input_Variables to papers_to_extract for dependent prompts
  papers_to_extract$Input_Variables <- extraction_results$Input_Variables
  
  # === Input Variable Resolution (depends on Input_Variables) ===
  message("\n=== Extracting Input Variable Resolution ===")
  extraction_results$Input_Variable_Resolution <- extract_single_variable(
    papers_to_extract, 
    prompt_input_resolution, 
    "Input_Variable_Resolution",
    depends_on = "Input_Variables"
  )
  
  # === Input Variable Source (depends on Input_Variables) [NEW] ===
  message("\n=== Extracting Input Variable Source ===")
  extraction_results$Input_Variable_Source <- extract_single_variable(
    papers_to_extract, 
    prompt_input_source, 
    "Input_Variable_Source",
    depends_on = "Input_Variables"
  )
  
  # === Analysis Resolution [FIXED] ===
  message("\n=== Extracting Analysis Resolution ===")
  extraction_results$Analysis_Resolution <- extract_single_variable(
    papers_to_extract, 
    prompt_analysis_resolution, 
    "Analysis_Resolution"
  )
  
  # === Spatial Method ===
  message("\n=== Extracting Spatial Method ===")
  extraction_results$Spatial_Method <- extract_single_variable(
    papers_to_extract, 
    prompt_spatial_method, 
    "Spatial_Method"
  )
  
  # Add Spatial_Method to papers_to_extract for dependent prompts
  papers_to_extract$Spatial_Method <- extraction_results$Spatial_Method
  
  # === Spatial Method Source (depends on Spatial_Method) [NEW] ===
  message("\n=== Extracting Spatial Method Source ===")
  extraction_results$Method_Source <- extract_single_variable(
    papers_to_extract, 
    prompt_method_source, 
    "Spatial_Method_Source",
    depends_on = "Spatial_Method"
  )
  
  # === Method Validation (depends on Spatial_Method) ===
  message("\n=== Extracting Method Validation ===")
  extraction_results$Method_Validation <- extract_single_variable(
    papers_to_extract, 
    prompt_method_validation, 
    "Method_Validation",
    depends_on = "Spatial_Method"
  )
  
  # === Tool ===
  message("\n=== Extracting Tool ===")
  extraction_results$Tool <- extract_single_variable(
    papers_to_extract, 
    prompt_tool, 
    "Tool"
  )
  
  # Add Tool to papers_to_extract for dependent prompts
  papers_to_extract$Tool <- extraction_results$Tool
  
  # === Tool Source (depends on Tool) [NEW] ===
  message("\n=== Extracting Tool Source ===")
  extraction_results$Tool_Source <- extract_single_variable(
    papers_to_extract, 
    prompt_tool_source, 
    "Tool_Source",
    depends_on = "Tool"
  )
  
  # === Output ===
  message("\n=== Extracting Output ===")
  extraction_results$Output <- extract_single_variable(
    papers_to_extract, 
    prompt_output, 
    "Output"
  )
  
  # Add Output to papers_to_extract for dependent prompts
  papers_to_extract$Output <- extraction_results$Output
  
  # === Output Resolution (depends on Output) ===
  message("\n=== Extracting Output Resolution ===")
  extraction_results$Output_Resolution <- extract_single_variable(
    papers_to_extract, 
    prompt_output_resolution, 
    "Output_Resolution",
    depends_on = "Output"
  )
  
  # === Climate Risk Assessment [NEW] ===
  message("\n=== Extracting Climate Risk Assessment ===")
  extraction_results$Climate_Risk_Assessment <- extract_single_variable(
    papers_to_extract, 
    prompt_climate_risk, 
    "Climate_Risk_Assessment"
  )
  
  # === Economics (depends on Output) [NEW] ===
  message("\n=== Extracting Economics ===")
  extraction_results$Economics <- extract_single_variable(
  papers_to_extract,
  prompt_economics,
  "Economics"
)
  
  
  # === Geographic Scope ===
  message("\n=== Extracting Geographic Scope ===")
  extraction_results$Geographic_Scope <- extract_single_variable(
    papers_to_extract, 
    prompt_geographic_scope, 
    "Geographic_Scope"
  )
  
  # === Narrative ===
  message("\n=== Extracting Narrative ===")
  extraction_results$Narrative <- extract_single_variable(
    papers_to_extract, 
    prompt_narrative, 
    "Narrative"
  )
  
  message("\n=== Code Data Availability ===")
  extraction_results$Code_Data_Availability <- extract_single_variable(
    papers_to_extract, 
    prompt_code_data_availability, 
    "Code_Data_Availability"
  )
  
  # Add extractor identifier
  extraction_results$Extractor <- "GPT-5-nano"
  
  message("\n✓ Extraction complete!")

```


# ============================================================================
# PART 6: SAVE RESULTS
# ============================================================================

```{r save_results, eval=FALSE}
# Save as RDS
saveRDS(extraction_results, file.path(OUT_DIR, "nbs_extraction_results_grey_lit.rds"))

# Save as CSV
write_csv(extraction_results, file.path(OUT_DIR, "nbs_extraction_results_grey_lit.csv"))

# Save as Excel
write_xlsx(extraction_results, file.path(OUT_DIR, "nbs_extraction_results.xlsx"))

message(glue("\nResults saved to: {OUT_DIR}"))
message(glue("  - nbs_extraction_results.rds"))
message(glue("  - nbs_extraction_results.csv"))
message(glue("  - nbs_extraction_results.xlsx"))

# ----- Summary statistics -----
summary_stats <- extraction_results %>%
  summarise(
    Total_Papers = n(),
    NbS_Subpractice_Extracted = sum(!is.na(NbS_Subpractice) & NbS_Subpractice != "NA"),
    Input_Variables_Extracted = sum(!is.na(Input_Variables) & Input_Variables != "NA"),
    Spatial_Method_Extracted = sum(!is.na(Spatial_Method) & Spatial_Method != "NA"),
    Method_Validation_Extracted = sum(!is.na(Method_Validation) & Method_Validation != "NA"),
    Tool_Extracted = sum(!is.na(Tool) & Tool != "NA"),
    Output_Extracted = sum(!is.na(Output) & Output != "NA"),
    Purpose_Extracted = sum(!is.na(Purpose) & Purpose != "NA"),
    Geographic_Scope_Extracted = sum(!is.na(Geographic_Scope) & Geographic_Scope != "NA"),
    Narrative_Extracted = sum(!is.na(Narrative) & Narrative != "NA")
  )

print(summary_stats)
```

# ============================================================================
# PART 7: PREVIEW RESULTS
# ============================================================================

```{r preview, eval=FALSE}
# Interactive preview
DT::datatable(
  extraction_results %>%
    mutate(across(where(is.character), ~ifelse(
      nchar(.) > 100,
      paste0("<span title='", ., "'>", substr(., 1, 100), "...</span>"),
      .
    ))),
  escape = FALSE,
  options = list(pageLength = 10, scrollX = TRUE),
  caption = "NbS Stocktake - Extraction Results"
)
```

# ============================================================================
# OPTIONAL: COST ESTIMATION
# ============================================================================

```{r cost_estimate}
# Estimate API costs before running full extraction
estimate_cost <- function(papers_df, n_variables = 12) {
  
  # Average text length
  avg_chars <- mean(nchar(papers_df$Text_For_Extraction), na.rm = TRUE)
  
  # Approximate tokens (rough: 4 chars = 1 token)
  avg_input_tokens <- avg_chars / 4
  avg_output_tokens <- 200  # Estimated average output
  
  n_papers <- nrow(papers_df)
  total_calls <- n_papers * n_variables
  
  # GPT-4o-mini pricing (as of 2024)
  # Input: $0.15 per 1M tokens

  # Output: $0.60 per 1M tokens
  
  input_cost <- (avg_input_tokens * total_calls / 1e6) * 0.15
  output_cost <- (avg_output_tokens * total_calls / 1e6) * 0.60
  total_cost <- input_cost + output_cost
  
  cat("\n=== COST ESTIMATE ===\n")
  cat(glue("Papers to process: {n_papers}\n"))
  cat(glue("Variables per paper: {n_variables}\n"))
  cat(glue("Total API calls: {total_calls}\n"))
  cat(glue("Avg input tokens per call: ~{round(avg_input_tokens)}\n"))
  cat(glue("Estimated cost: ${round(total_cost, 2)}\n"))
  cat("=====================\n")
  
  invisible(total_cost)
}

# Run cost estimate
if (exists("papers_to_extract")) {
  estimate_cost(papers_to_extract)
}
```

# ============================================================================
# OPTIONAL: TEST ON SMALL SAMPLE
# ============================================================================

```{r test_sample, eval=FALSE}
# ============================================================================
# OPTIONAL: TEST ON SMALL SAMPLE (5 papers per NbS Practice, ALL variables)
# ============================================================================
set.seed(123)

# Sample up to 5 papers per NbS practice (fixed slice_sample issue)
test_sample <- papers_to_extract %>%
  group_by(NbS_Practice) %>%
  slice_head(n = 5) %>%
  ungroup() %>%
  slice_sample(prop = 5)  # Shuffle the result

message(glue("Testing on {nrow(test_sample)} papers across {n_distinct(test_sample$NbS_Practice)} NbS practices..."))

# Check distribution
test_sample %>% count(NbS_Practice) %>% print()

# Initialize test results dataframe with metadata
test_results <- test_sample %>%
  select(
    File, 
    NbS_Practice, 
    NbS_Cluster,
    Text_For_Extraction
  )

# ----- Extract ALL variables sequentially -----

# === NbS Subpractice ===
message("\n=== Extracting NbS Subpractice ===")
test_results$NbS_Subpractice <- extract_single_variable(
  test_sample, 
  prompt_nbs_subpractice, 
  "NbS_Subpractice"
)

# === Input Variables ===
message("\n=== Extracting Input Variables ===")
test_results$Input_Variables <- extract_single_variable(
  test_sample, 
  prompt_input_variables, 
  "Input_Variables"
)

# Add Input_Variables to test_sample for dependent prompts
test_sample$Input_Variables <- test_results$Input_Variables

# === Input Variable Resolution (depends on Input_Variables) ===
message("\n=== Extracting Input Variable Resolution ===")
test_results$Input_Variable_Resolution <- extract_single_variable(
  test_sample, 
  prompt_input_resolution, 
  "Input_Variable_Resolution",
  depends_on = "Input_Variables"
)

# === Input Variable Source (depends on Input_Variables) ===
message("\n=== Extracting Input Variable Source ===")
test_results$Input_Variable_Source <- extract_single_variable(
  test_sample, 
  prompt_input_source, 
  "Input_Variable_Source",
  depends_on = "Input_Variables"
)

# === Analysis Resolution ===
message("\n=== Extracting Analysis Resolution ===")
test_results$Analysis_Resolution <- extract_single_variable(
  test_sample, 
  prompt_analysis_resolution, 
  "Analysis_Resolution"
)

# === Spatial Method ===
message("\n=== Extracting Spatial Method ===")
test_results$Spatial_Method <- extract_single_variable(
  test_sample, 
  prompt_spatial_method, 
  "Spatial_Method"
)

# Add Spatial_Method to test_sample for dependent prompts
test_sample$Spatial_Method <- test_results$Spatial_Method

# === Spatial Method Source (depends on Spatial_Method) ===
message("\n=== Extracting Spatial Method Source ===")
test_results$Method_Source <- extract_single_variable(
  test_sample, 
  prompt_method_source, 
  "Spatial_Method_Source",
  depends_on = "Spatial_Method"
)

# === Method Validation (depends on Spatial_Method) ===
message("\n=== Extracting Method Validation ===")
test_results$Method_Validation <- extract_single_variable(
  test_sample, 
  prompt_method_validation, 
  "Method_Validation",
  depends_on = "Spatial_Method"
)

# === Tool ===
message("\n=== Extracting Tool ===")
test_results$Tool <- extract_single_variable(
  test_sample, 
  prompt_tool, 
  "Tool"
)

# Add Tool to test_sample for dependent prompts
test_sample$Tool <- test_results$Tool

# === Tool Source (depends on Tool) ===
message("\n=== Extracting Tool Source ===")
test_results$Tool_Source <- extract_single_variable(
  test_sample, 
  prompt_tool_source, 
  "Tool_Source",
  depends_on = "Tool"
)

# === Output ===
message("\n=== Extracting Output ===")
test_results$Output <- extract_single_variable(
  test_sample, 
  prompt_output, 
  "Output"
)

# Add Output to test_sample for dependent prompts
test_sample$Output <- test_results$Output

# === Output Resolution (depends on Output) ===
message("\n=== Extracting Output Resolution ===")
test_results$Output_Resolution <- extract_single_variable(
  test_sample, 
  prompt_output_resolution, 
  "Output_Resolution",
  depends_on = "Output"
)

# === Climate Risk Assessment ===
message("\n=== Extracting Climate Risk Assessment ===")
test_results$Climate_Risk_Assessment <- extract_single_variable(
  test_sample, 
  prompt_climate_risk, 
  "Climate_Risk_Assessment"
)

# === Economics ===
message("\n=== Extracting Economics ===")
test_results$Economics <- extract_single_variable(
  test_sample, 
  prompt_economics, 
  "Economics"
)

# === Geographic Scope ===
message("\n=== Extracting Geographic Scope ===")
test_results$Geographic_Scope <- extract_single_variable(
  test_sample, 
  prompt_geographic_scope, 
  "Geographic_Scope"
)

# === Narrative ===
message("\n=== Extracting Narrative ===")
test_results$Narrative <- extract_single_variable(
  test_sample, 
  prompt_narrative, 
  "Narrative"
)

# === Code Data Availability ===
message("\n=== Extracting Code Data Availability ===")
test_results$Code_Data_Availability <- extract_single_variable(
  test_sample, 
  prompt_code_data_availability, 
  "Code_Data_Availability"
)

# Add extractor identifier
test_results$Extractor <- "GPT-5-nano"

message("\n✓ Test extraction complete!")

# ----- Save test results -----
saveRDS(test_results, file.path(OUT_DIR, "nbs_test_extraction_results2.rds"))
write_csv(test_results, file.path(OUT_DIR, "nbs_test_extraction_results2.csv"))

message(glue("\nTest results saved to: {OUT_DIR}"))

# ----- Preview test results -----
DT::datatable(
 test_results %>%
    select(-Text_For_Extraction) %>%
    mutate(across(where(is.character), ~ifelse(
      nchar(.) > 80,
      paste0(substr(., 1, 80), "..."),
      .
    ))),
  options = list(pageLength = 10, scrollX = TRUE),
  caption = glue("Test Extraction Results - {nrow(test_results)} papers ({n_distinct(test_results$NbS_Practice)} NbS Practices)")
)

# ----- Summary by NbS Practice -----
test_summary <- test_results %>%
  group_by(NbS_Practice) %>%
  summarise(
    n_papers = n(),
    input_vars_extracted = sum(!is.na(Input_Variables) & Input_Variables != "NA"),
    spatial_method_extracted = sum(!is.na(Spatial_Method) & Spatial_Method != "NA"),
    tool_extracted = sum(!is.na(Tool) & Tool != "NA"),
    output_extracted = sum(!is.na(Output) & Output != "NA"),
    .groups = "drop"
  )

print(test_summary)
```

```{r}
# Load the Baldwin paper text
baldwin_txt <- load_txt_file('Baldwin et al. - 2022 - Geospatial Analysis and Land Suitability for "FloodWise" Practices Nature-Based Solutions for Flood.pdf')

# Check text length
cat("Text length:", nchar(baldwin_txt), "chars\n")

# Clip if needed
baldwin_txt_clipped <- clip_text(baldwin_txt, MAX_CHARS)

# 1. Extract Input Variables
cat("\n=== Extracting Input Variables ===\n")
input_vars_response <- safe_chat(prompt_input_variables(baldwin_txt_clipped))
cat("Input Variables:\n", input_vars_response$response, "\n")

# 2. Extract Input Variable Resolution (depends on Input Variables)
cat("\n=== Extracting Input Variable Resolution ===\n")
input_res_response <- safe_chat(prompt_input_resolution(baldwin_txt_clipped, input_vars_response$response))
cat("Input Resolution:\n", input_res_response$response, "\n")

# 3. Extract Input Variable Source (depends on Input Variables)
cat("\n=== Extracting Input Variable Source ===\n")
input_source_response <- safe_chat(prompt_input_source(baldwin_txt_clipped, input_vars_response$response))
cat("Input Source:\n", input_source_response$response, "\n")
```


